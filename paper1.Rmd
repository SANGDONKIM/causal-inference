---
title: "Making Sense of Sensitivity: Extending Omitted Variable Bias"
description: |
  논문 요약 
author:
  - name: SangDon Kim
date: "`r Sys.Date()`"
output:
  distill::distill_article:
    code_folding: false
    toc: true
css: [style.css]
---

# Frisch-waugh-Lovell theorem

설명 추가 

$X_1, X_2$는 독립변수의 집합을 의미함

$$
\begin{align*}
y = X_1 \beta_1 + X_2 \beta_2 + \epsilon
\end{align*}
$$ 추정하고자 하는 $\hat{\beta}$는 다음과 같음

1.  $y ~ \sim X_1$의 잔차 $\longrightarrow$ $y^*$

    -   $y ~ \sim X_1$로 회귀모형을 fitting해서 잔차 $y^*$을 구한다.

2.  $X_2 ~ \sim X_1$의 잔차 $\longrightarrow$ $X_2^*$

    -   $X_2 ~ \sim X_1$로 회귀모형을 fitting해서 잔차 $X_2^*$를 구한다.

3.  $y^* \sim X_2^*$ $\longrightarrow$ $\hat{\beta}_2$

    -   잔차 $y^*$와 잔차 $X_2^*$를 회귀모형으로 fitting해서 얻은 coefficient는 $\hat{\beta}_2$와 같다.



$$
\begin{align*}
y = X_1 \hat{\beta_1} + X_2 \hat{\beta_2} + e
\end{align*}
$$ normal equation으로 표현하면 다음과 같음

$$
\begin{align*}
\begin{bmatrix}
X_1^t X_1 & X_1^t X_2 \\
X_2^t X_1 & X_1^2 X_2
\end{bmatrix}
\begin{bmatrix}
\hat{\beta_1}  \\
\hat{\beta_2} 
\end{bmatrix} = 
\begin{bmatrix}
X_1^t y  \\
X_2^t y 
\end{bmatrix} 
\end{align*}
$$

먼저 $\hat{\beta_1}$에 대해 풀면 다음과 같다.

$$
\begin{align*}
(X_1^tX_1)\hat{\beta_1} + (X_1^tX_2)\hat{\beta_2} &= X_1^ty \\
(X_1^tX_1)\hat{\beta_1} &= X_1^ty - (X_1^tX_2)\hat{\beta_2} \\ 
\hat{\beta_1} &= (X_1^tX_1)^{-1}X_1^ty - (X_1^tX_1)^{-1}X_1^tX_2\hat{\beta_2} \\
\hat{\beta_1} &= (X_1^tX_1)^{-1}X_1^t(y - X_2\hat{\beta_2}) 
\end{align*}
$$

다음으로 $\hat{\beta_2}$에 대해 정리하면 다음과 같다.

$$
\begin{align*}
(X_2^tX_1)\hat{\beta_1} + (X_2^tX_2)\hat{\beta_2} &= X_2^ty \\
(X_2^tX_1) (X_1^tX_1)^{-1}X_1^t(y - X_2\hat{\beta_2}) +(X_2^tX_2)\hat{\beta_2} &= X_2^ty \\ 
X_2^tX_1(X_1^tX_1)^{-1}X_1^ty - X_2^tX_1(X_1^tX_1)^{-1}X_2^t\hat{\beta}_2 + X_2^tX_2\hat{\beta}_2 &=X_2^ty \\
X_2^ty - X_2^tX_1(X_1^tX_1)^{-1}X_1^ty &= X_2^tX_2\hat{\beta}_2 - X_2^tX_1(X_1^tX_1)^{-1}X_2^t\hat{\beta}_2 \\ 
X_2^t(I - X_1(X_1^tX_1)^{-1}X_1^t)y &= [X_2^t(I - X_1(X_1^tX_1)^{-1}X_1^t)X_2]\hat{\beta}_2 \\
\hat{\beta}_2 &= [X_2^t(I - X_1(X_1^tX_1)^{-1}X_1^t)X_2]^{-1}X_2^t(I - X_1(X_1^tX_1)^{-1}X_1^t)y \\
&=[X_2^tM_1X_2]^{-1}X_2^tM_1y, \quad M_1 = I - X_1(X_1^tX_1)^{-1}X_1^t
\end{align*}
$$

회귀분석에서 $M$은 residual maker로 $My$는 $y \sim X$의 잔차를 의미한다.

$$
\begin{align*}
e &= y - X\hat{\beta} \\ 
&=y - X(X^tX)^{-1}X^ty \\ 
&=(I - X(X^tX)^{-1}X^t)y \\ 
&=My
\end{align*}
$$

따라서 위의 식 $\hat{\beta}_2 = [X_2^tM_1X_2]^{-1}X_2^tM_1y$에서

$M_1y$는 $y \sim X_1$의 잔차, $M_1X_2$는 $X_2 \sim X_1$를 의미한다.

$$
\begin{align*}
\hat{\beta}_2 &= [X_2^tM_1X_2]^{-1}X_2^tM_1y \\ 
&=[X_2^tM_1^tM_1X_2]^{-1}X_2^tM_1^tM_1y, \quad M_1^tM1 = M_1 : \text{idempotent matrix} \\ 
&= [X_2^{*t}X_2^*]^{-1}X_2^{*t}y^*, \quad X_2^* = M_1X_2, \quad y^* = M_1y
\end{align*}
$$

즉, 정리하면 다음과 같다.

$$
\begin{align*}
y = X_1\beta_1 + X_2\beta_2 + \epsilon \longrightarrow y &= X_1\hat{\beta}_1 + X_2\hat{\beta}_2 + e \\ 
\therefore \hat{\beta}_2 &= [X_2^{*t}X_2^*]^{-1}X_2^{*t}y^*, \quad X_2^* = M_1X_2, \quad y^* = M_1y
\end{align*}
$$

## Example

-   $D$ : treatment variable

-   $X$ : observed covariates

-   $Z$ : unobserved covariates

$$
\begin{align*}
Y = \hat{\tau}D + X\hat{\beta} + \hat{\gamma}Z + \hat{\epsilon}_{null}
\end{align*}
$$

**Frisch-waugh-Lovell theorem**을 적용하면
$Y = \hat{\tau}D + X\hat{\beta} + \hat{\gamma}Z + \hat{\epsilon}_{null}$에 **FWL**을 적용하면

1.  $Y ~ \sim X$의 잔차 $\longrightarrow$ $Y^{\perp X}$

2.  $D ~ \sim X$의 잔차 $\longrightarrow$ $D^{\perp X}$

3.  $Z ~ \sim X$의 잔차 $\longrightarrow$ $Z^{\perp X}$

4.  $Y^{\perp X} \sim D^{\perp X} + Z^{\perp X}$ $\longrightarrow$ $\hat{\tau}, \, \hat{\gamma}$

    -   $Y^{\perp X} = \hat{\tau}D^{\perp X} + \hat{\gamma}Z^{\perp X}$

```{r}
set.seed(13)
N = 10000

df <- data.frame(
    Z = rnorm(N, 1),
    X = rnorm(N, 1.5),
    D = rnorm(N, 2.5), 
    Y = rnorm(N, 3))

YperpX <- lm(Y ~ X, df)$residuals
DperpX <- lm(D ~ X, df)$residuals
ZperpX <- lm(Z ~ X, df)$residuals

resid_df <- data.frame(YperpX, DperpX, ZperpX)

print(coef(lm(YperpX ~ DperpX+ZperpX, resid_df))[c(2, 3)], digits = 2)

```

$\hat{\tau} = -0.00072,\quad \hat{\gamma} = 0.01351$
```{r}
print(coef(lm(Y~D+X+Z, df))[c(2, 4)], digits = 2)
```




$$
\begin{align*}
Y = \hat{\tau}_{res}D + X\hat{\beta}_{res} + \hat{\epsilon}_{res}
\end{align*}
$$



$Y = \hat{\tau}_{res}D + X\hat{\beta}_{res} + \hat{\epsilon}_{res}$에 **FWL**을 적용하면

1.  $y ~ \sim X$의 잔차 $\longrightarrow$ $Y^{\perp X}$

2.  $D ~ \sim X$의 잔차 $\longrightarrow$ $D^{\perp X}$

3.  $Y^{\perp X} \sim D^{\perp X}$ $\longrightarrow$ $\hat{\tau}_{res}$

```{r}
set.seed(13)
N = 10000

df <- data.frame(
    X = rnorm(N, 1.5),
    D = rnorm(N, 2.5), 
    Y = rnorm(N, 3))

YperpX <- lm(Y ~ X, df)$residuals
DperpX <- lm(D ~ X, df)$residuals

resid_df <- data.frame(YperpX, DperpX)

print(coef(lm(YperpX ~ DperpX, resid_df))[2], digits = 2)

```

$\hat{\tau}_{res} = 0.0078$

```{r}
print(coef(lm(Y~D+X, df))[2], digits = 2)
```



## 3.1 The traditional omitted variable bias


$$
\begin{align*}
\hat{\tau}_{res} &= \frac{cov(D^{\perp X}, Y^{\perp X})}{var(D^{\perp X})} \\ 
&= \frac{cov(D^{\perp X},\hat{\tau}D^{\perp X} + \hat{\gamma}Z^{\perp X})}{var(D^{\perp X})} \\ 
&= \frac{\hat{\tau}cov(D^{\perp X},D^{\perp X}) + \hat{\gamma}cov(D^{\perp X}, Z^{\perp X})}{var(D^{\perp X})} \\
&=\hat{\tau} + \hat{\gamma} \cdot \hat{\delta}, \quad \hat{\delta} = \frac{cov(D^{\perp X}, Z^{\perp X})}{var(D^{\perp X})}, \quad \hat{\gamma} = \frac{cov(Y^{\perp X, D}, Z^{\perp X, D})}{var(Z^{\perp X, D})}
\end{align*}
$$

따라서 unobserved confounder에 의한 추정량의 bias는 다음과 같다.

$$
\begin{align*}
\hat{bias} = \hat{\tau}_{res} - \hat{\tau} =  \hat{\gamma} \cdot \hat{\delta}
\end{align*}
$$

$Z$는 unobserved confounder이므로 $\hat{\gamma}, \, \hat{\delta}$의 부호를 알 수 없다. 따라서 unobserved confounder의 추정량에 영향을 미치는 크기를 고려해야 한다. 즉, 연구의 주요 결론에 영향을 줄 정도로 추정량을 변경하려면 unobserved confounder $Z$의 효과는 어느 정도 크기여야 하는가?

이는 sensitivity analysis를 통해 파악할 수 있다.

## contour plot

![](images/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202022-06-08%20%EC%98%A4%EC%A0%84%2012.51.39.png)


## OVB with the partial $R^2$ parameterization


$$
\begin{align*}
\hat{bias} &= \hat{\gamma} \cdot \hat{\delta} \\ 
&=\sqrt{\frac{R^2_{Y \sim Z|D, X} \cdot R^2_{D \sim Z|X}}{1-R^2_{D \sim Z|X}}} \cdot \frac{sd(Y^{\perp X,D})}{sd(D^{\perp X})} \\
&=\hat{se}(\hat{\tau}_{res})\cdot\sqrt{\frac{R^2_{Y \sim Z|D, X} \cdot R^2_{D \sim Z|X}}{1-R^2_{D \sim Z|X}}}(df)
\end{align*}
$$




# 참고자료

<https://bookdown.org/ts_robinson1994/10_fundamental_theorems_for_econometrics/frisch.html>

<https://arelbundock.com/posts/robustness_values/>

<https://web.stanford.edu/~mrosenfe/soc_meth_proj3/matrix_OLS_2_Beck_UCSD.pdf>
